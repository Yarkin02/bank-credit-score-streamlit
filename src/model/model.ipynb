{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Score Classification Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import catboost as cb\n",
    "from catboost import CatBoostClassifier\n",
    "import re\n",
    "import pickle\n",
    "from joblib import dump\n",
    "import shap\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "data = pd.read_csv('/Users/apple/Desktop/Bank-Credit-Score-Streamlit/src/data/credit_score_train.csv')\n",
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# İşe yaramayan sütunlar droplandı.\n",
    "drop_list = [\"ID\", \"Customer_ID\", \"Name\", \"SSN\"]\n",
    "df = df.drop(columns=drop_list, axis = 1)\n",
    "\n",
    "# Kategorik Sütunlar için Düzenlemeler;\n",
    "\n",
    "## Occupation sütunu için düzenleme:\n",
    "df['Occupation'].replace(\"_______\", \"Other\", inplace = True)\n",
    "\n",
    "# NaN değerlerini koruyalım\n",
    "df['Payment_Behaviour'] = df['Payment_Behaviour'].replace('!@9#%8', np.nan)\n",
    "\n",
    "# NaN değerlerini rastgele dolduralım\n",
    "random_fill = df['Payment_Behaviour'].dropna().sample(df['Payment_Behaviour'].isnull().sum(), random_state=42).values\n",
    "df.loc[df['Payment_Behaviour'].isnull(), 'Payment_Behaviour'] = random_fill\n",
    "\n",
    "# Tüm değerleri string'e çevirelim\n",
    "df['Payment_Behaviour'] = df['Payment_Behaviour'].astype(str)\n",
    "\n",
    "# Split işlemini uygulayalım\n",
    "df['Payment_spent'] = df['Payment_Behaviour'].apply(lambda x: x.split('_')[0])\n",
    "df['Payments_value'] = df['Payment_Behaviour'].apply(lambda x: x.split('_')[2])\n",
    "\n",
    "# Payment Behaviour droplandı.\n",
    "df = df.drop(columns = 'Payment_Behaviour', axis = 1)\n",
    "\n",
    "# Type_of_Loan değişkeni ile Num_Of_Loan değişkeni ile yüksek korelasyona sahip olduğundan droplandı.\n",
    "df = df.drop('Type_of_Loan', axis = 1)\n",
    "\n",
    "# Annual_Income değişkeni Monthly_Inhand_Salary değişkeni ile yüksek korelasyona sahip olduğundan droplandı.\n",
    "df = df.drop('Annual_Income', axis = 1)\n",
    "\n",
    "## Credit Mix sütunu için düzenleme:\n",
    "df['Credit_Mix'].replace(\"_\", np.nan, inplace=True)\n",
    "\n",
    "def fill_nan_categorical(df, column):\n",
    "    # Sütundaki değerlerin dağılımını hesapla\n",
    "    value_counts = df[column].value_counts(normalize=True)\n",
    "    \n",
    "    # NaN değerlerini oransal olarak doldur\n",
    "    def fill_nan(value):\n",
    "        if pd.isna(value):\n",
    "            return np.random.choice(value_counts.index, p=value_counts.values)\n",
    "        return value\n",
    "    \n",
    "    # Fonksiyonu sütuna uygula\n",
    "    return df[column].apply(fill_nan)\n",
    "\n",
    "df['Credit_Mix'] = fill_nan_categorical(df, 'Credit_Mix')\n",
    "\n",
    "# 'Media_Manager' değerini 'Media Manager' olarak değiştirme\n",
    "df['Occupation'] = df['Occupation'].replace('Media_Manager', 'Media Manager')\n",
    "\n",
    "# Kategorik ve numerik sütunlar seçildi.\n",
    "cat_cols = [\"Month\", \"Occupation\", \"Payment_of_Min_Amount\", \"Credit_Mix\", \"Credit_Score\", \"Credit_History_Age\",\"Payment_spent\", \"Payments_value\"]\n",
    "num_cols = [col for col in df.columns if col not in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kategorik sütunların sahip olduğu unique değerlerin countsları\n",
    "for col in cat_cols:\n",
    "    print(df[col].value_counts())\n",
    "    print(\"- - - - - - - - - - - -\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sayısal Sütunlar için Düzenlemeler;\n",
    "\n",
    "# Sayısallığı bozan karakterleri bulma fonksiyonu\n",
    "def find_non_numeric_characters(value):\n",
    "    if isinstance(value, str):\n",
    "        # Sadece sayılar ve nokta dışında kalan karakterleri bul\n",
    "        non_numeric_chars = re.findall(r'[^0-9.]', value)\n",
    "        if non_numeric_chars:\n",
    "            return ''.join(non_numeric_chars)\n",
    "    return None\n",
    "\n",
    "# Tüm sayısal olmayan karakterleri bul ve listele\n",
    "non_numeric_values = []\n",
    "\n",
    "for col in num_cols:\n",
    "    for idx, value in enumerate(df[col]):\n",
    "        non_numeric_chars = find_non_numeric_characters(value)\n",
    "        if non_numeric_chars:\n",
    "            non_numeric_values.append((idx, col, value, non_numeric_chars))\n",
    "\n",
    "# Sayısal olmayan karakterleri göster\n",
    "for idx, col, original_value, non_numeric_chars in non_numeric_values:\n",
    "    print(f\"Satır {idx}, Sütun {col}: '{original_value}' sayısal olmayan karakterler: '{non_numeric_chars}'\")\n",
    "\n",
    "def clean_numeric(value):\n",
    "    if isinstance(value, str):\n",
    "        # Sadece sayılar ve nokta dışındaki karakterleri kaldır\n",
    "        value = re.sub(r'[^0-9.]', '', value)\n",
    "    try:\n",
    "        return float(value)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "# Tüm sayısal olmayan karakterleri bul ve düzelt\n",
    "for col in num_cols:\n",
    "    df[col] = df[col].apply(clean_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Credit_History_Age değişkeni ** Year and ** Month şeklinde verilmişti, Year'dan önceki değer seçilip 12 ile çarpıldı, Month'dan önceki değerle toplanıp\n",
    "# Credit_History_Months adında kredi geçmişini ay cinsinden ifade eden yeni numerik bir değişken oluşturuldu.\n",
    "\n",
    "# Yıl ve ay cinsinden veriyi temizleme ve dönüştürme fonksiyonu\n",
    "def clean_and_convert_to_months(value):\n",
    "    if isinstance(value, str):\n",
    "        # Yıl ve ay bilgilerini ay cinsine dönüştürme\n",
    "        parts = value.split(' ')\n",
    "        years = int(parts[0])\n",
    "        months = int(parts[3])\n",
    "        total_months = years * 12 + months\n",
    "        return total_months\n",
    "    return None\n",
    "\n",
    "# Yeni sütun oluşturma ve işlemi uygulama\n",
    "df['Credit_History_Months'] = df['Credit_History_Age'].apply(clean_and_convert_to_months)\n",
    "\n",
    "df = df.drop(columns = 'Credit_History_Age', axis = 1)\n",
    "\n",
    "df['Credit_History_Months'] = df['Credit_History_Months'].fillna(df['Credit_History_Months'].mean())\n",
    "\n",
    "num_cols.append('Credit_History_Months')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri setinde veri girişinden kaynaklı olduğunu düşündüğüm absürt değerler bulunuyordu bu yüzden bu veriler silindi.\n",
    "# Aykırı verilerin ortadan kaldırılması.\n",
    "bounds = {}\n",
    "for col in num_cols:\n",
    "    q1 = df[col].quantile(0.05)\n",
    "    q3 = df[col].quantile(0.95)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    bounds[col] = {'lower_bound': lower_bound, 'upper_bound': upper_bound}\n",
    "\n",
    "# Belirli aralık dışındaki değerleri çıkaralım\n",
    "for col in num_cols:\n",
    "    df = df[(df[col] >= bounds[col]['lower_bound']) & (df[col] <= bounds[col]['upper_bound'])]\n",
    "\n",
    "# Banka hesabı sayısında ve ödemelerde gerçekleşen ortalama gecikme sayısında negatif veriler mevcuttu\n",
    "# Ortalama gecikme sayısındaki negatif değerler kişilerin borcunu daha erkenden ödeyebileceğinden kaynaklı olabilir fakat\n",
    "# veri seti sağlayacısında böyle bir bilgi bulunmadığından dolayı ve her iki koşul için de frekansın düşük olduğundan dolayı\n",
    "# bu veriler droplandı.\n",
    "\n",
    "# Her iki koşulu da sağlamayan satırları seç\n",
    "df = df[~((df['Delay_from_due_date'] >= -5) & (df['Delay_from_due_date'] < 0)) & \n",
    "        (df['Num_Bank_Accounts'] != -1)]\n",
    "\n",
    "# DataFrame'i sıfırdan indeksle\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy aşamasında tüm kategoriler belirli olduğu(Olmayan bir sınıf seçilemeyecek şekilde ayarlanacak) için encoding işlemini mapleme yöntemi tercih edilerek yapıldı.\n",
    "\n",
    "## ENCODING\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "month_encode = {'January':1, 'February':2, 'March':3, 'April':4,\n",
    "                'May':5, 'June':6, 'July':7, 'August':8}\n",
    "\n",
    "df['Month'] = df['Month'].map(month_encode)\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "occ_encode = {'Lawyer':1, 'Engineer':2, 'Mechanic':3, 'Teacher':4, 'Architect':5,\n",
    "              'Scientist':6, 'Accountant':7, 'Entrepreneur':8, 'Developer':9,\n",
    "              'Doctor':10, 'Media Manager':11, 'Journalist':12, 'Manager':13,\n",
    "              'Musician':14, 'Writer':15, 'Other':16}\n",
    "\n",
    "df['Occupation'] = df['Occupation'].map(occ_encode)\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "payment_of_encode = {'No':0, 'Yes':1, 'NM':2}\n",
    "\n",
    "df[\"Payment_of_Min_Amount\"] = df[\"Payment_of_Min_Amount\"].map(payment_of_encode)\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "# OrdinalEncoder ile kategorileri belirleme\n",
    "oe_features = OrdinalEncoder(categories=[\n",
    "    ['Bad', 'Standard', 'Good'],          # Credit_Mix\n",
    "    ['Low', 'High'],                      # Payment_spent\n",
    "    ['Small', 'Medium', 'Large']          # Payments_value\n",
    "])\n",
    "\n",
    "# Encoder'ı fit ve transform etme\n",
    "df[['Credit_Mix',\n",
    "       'Payment_spent',\n",
    "         'Payments_value']] = oe_features.fit_transform(df[['Credit_Mix', 'Payment_spent', 'Payments_value']])\n",
    "\n",
    "oe_target = OrdinalEncoder(categories=[['Poor', 'Standard', 'Good']])\n",
    "df['Credit_Score'] = oe_target.fit_transform(df[['Credit_Score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of the Spearman correlation\n",
    "target = 'Credit_Score'\n",
    "df_ordered = pd.concat([df.drop(target,axis=1), df[target]],axis=1)\n",
    "corr = df_ordered.corr(method='spearman')\n",
    "\n",
    "# Create a mask so that we see the correlation values only once\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask,1)] = True\n",
    "\n",
    "# Plot the heatmap correlation\n",
    "plt.figure(figsize=(17,10), dpi=80)\n",
    "sns.heatmap(corr, mask=mask, annot=True,fmt='.2f', linewidths=0.2)\n",
    "#plt.savefig('corr_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Grafiği göster (isteğe bağlı)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bağımlı ve bağımsız değişkenleri seç\n",
    "y = df['Credit_Score']                  \n",
    "X = df.drop(['Credit_Score'], axis=1)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "\n",
    "X[num_cols] = scaler.fit_transform(X[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model oluştur\n",
    "model = CatBoostClassifier(random_state=42, iterations=2000, learning_rate=0.01, verbose=0, thread_count=-1)\n",
    "\n",
    "# KFold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Skorları saklamak için listeler\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Cross-validation döngüsü\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    \n",
    "    # Modeli eğit\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Tahminler yap\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Skorları hesapla ve sakla\n",
    "    accuracy_scores.append(accuracy_score(y_val, y_pred))\n",
    "    precision_scores.append(precision_score(y_val, y_pred, average='weighted'))\n",
    "    recall_scores.append(recall_score(y_val, y_pred, average='weighted'))\n",
    "    f1_scores.append(f1_score(y_val, y_pred, average='weighted'))\n",
    "    \n",
    "# Sonuçları yazdır\n",
    "print(\"Cross-validation Accuracy scores:\", accuracy_scores)\n",
    "print(\"Mean Accuracy score:\", np.mean(accuracy_scores))\n",
    "print(\"Mean Precision score:\", np.mean(precision_scores))\n",
    "print(\"Mean Recall score:\", np.mean(recall_scores))\n",
    "print(\"Mean F1 score:\", np.mean(f1_scores))\n",
    "\n",
    "model_components = {\n",
    "    'model': model,\n",
    "    'scaler': scaler,\n",
    "    'oe_features': oe_features,\n",
    "    'oe_target': oe_target\n",
    "}\n",
    "\n",
    "dump(model_components, 'credit_score_model_components.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'model' is your CatBoostClassifier and 'df' is your DataFrame\n",
    "\n",
    "# Get feature importances\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Get feature names\n",
    "feature_names = df.drop('Credit_Score', axis=1).columns\n",
    "\n",
    "# Sort indices in descending order based on importances\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title(\"Feature Importances with CatBoost Classifier\", fontsize=18)\n",
    "plt.barh(range(len(indices)), importances[indices], align=\"center\")\n",
    "plt.yticks(range(len(indices)), feature_names[indices], rotation='horizontal', fontsize=12)\n",
    "plt.xlabel('Feature Importance', fontsize=14)\n",
    "plt.ylim([-1, len(indices)])\n",
    "plt.savefig('feature_importances.png', dpi = 300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
